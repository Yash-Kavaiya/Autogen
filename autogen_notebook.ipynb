{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyautogen[gemini,retrievechat,lmm] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_gemini_vision = autogen.config_list_from_json(\n",
    "    \"./OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro-vision\"],\n",
    "    },\n",
    ")\n",
    "seed = 25  # for caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Gemini Vision):\n",
      "\n",
      "Describe what is in this image?\n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mGemini Vision\u001b[0m (to user_proxy):\n",
      "\n",
      " This is a user interacting with an assistant via a chat interface. The user gives instructions, and the assistant responds by executing the code and returning the results. In this particular instance, the user is asking the assistant to plot a chart of stock prices and then make changes to the chart. The assistant is able to complete these tasks because it has been trained on a large dataset of code and has been configured to write Python code.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Describe what is in this image?\\n<img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.', 'role': 'assistant'}, {'content': ' This is a user interacting with an assistant via a chat interface. The user gives instructions, and the assistant responds by executing the code and returning the results. In this particular instance, the user is asking the assistant to plot a chart of stock prices and then make changes to the chart. The assistant is able to complete these tasks because it has been trained on a large dataset of code and has been configured to write Python code.', 'role': 'user'}], summary=' This is a user interacting with an assistant via a chat interface. The user gives instructions, and the assistant responds by executing the code and returning the results. In this particular instance, the user is asking the assistant to plot a chart of stock prices and then make changes to the chart. The assistant is able to complete these tasks because it has been trained on a large dataset of code and has been configured to write Python code.', cost={'usage_including_cached_inference': {'total_cost': 0.000261, 'gemini-pro-vision': {'cost': 0.000261, 'prompt_tokens': 267, 'completion_tokens': 85, 'total_tokens': 352}}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = MultimodalConversableAgent(\n",
    "    \"Gemini Vision\", llm_config={\"config_list\": config_list_gemini_vision, \"seed\": seed}, max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", human_input_mode=\"NEVER\", max_consecutive_auto_reply=0)\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    image_agent,\n",
    "    message=\"\"\"Describe what is in this image?\n",
    "<img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
